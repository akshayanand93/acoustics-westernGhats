---
editor_options: 
  chunk_output_type: console
---

Install necessary libraries
```{r}
library(seewave)
library(warbleR)
library(tuneR)
# remotes::install_github("jeffreyevans/soundscapes")
library(soundscapes)
library(stringi)
library(tidyverse)

# Source any custom/other internal functions necessary for analysis
source("code\\01_internal-functions.R")

```


Exploratory data analysis - Here I will try a few different functions from the seewave package in R to get a better sense of the distribution of frequencies over time
```{r}
# Read a sample .wav file
a <- tuneR::readWave("data\\20200307_083000.wav")

# Soundscape frequency spectrum of a time wave

# This function returns a kHz binned spectrum as described by Kasten et al. (2012) for the description of a soundscape.
# This function essentially creates a bar plot of frequencies in kHZ by amplitude values
s_spectr <- soundscapespec(a)

```

Acoustic Space Use (ASU)

We are interested in creating a three-dimensional matrix of acoustic activity (x=hour, y=acoustic frequencies, z=proportion of all recordings in each time/frequency bin)

Aide et al. 2017: We aggregated recordings at time scale of hour of day and used a frequency bin size of 86.13 Hz and an amplitude filtering threshold of 0.02. So if the sampling rate is 22000 Hz, that would mean - 22000/86.13 ~ 256 frequency bins to divide up the frequency space. In this paper, there would be 24hr*256 bins = 6144 time/frequency bins

Campos-Cerqueira et al. 2019: We aggregated recordings at the time scale of hour of day (24 h), used a frequency bin size of 172 Hz, and an amplitude filtering threshold of 0.003. So if the sampling rate is 22000 Hz, that would mean - 22000/172 ~ 128 frequency bins. This resulted in a three‐dimensional (x = hour, y = acoustic frequency, z = proportion of all recordings in each time/frequency bin with a frequency peak value > 0.003 amplitude) matrix of acoustic activity with a total of 3,072 time/frequency bins (24 h × 128 frequency bins).

Campos-Cerqueira and Aide 2017: To calculate the amplitude, we used the meanspec (f = 44,100, wl = 256, wn = “hanning”) and fpeaks (threshold = 0.1, freq = 172) function from the seewave package in R (Sueur et al., 2008a). The value of each peak was normalized using the maximum amplitude value within all recordings in the soundscape (i.e., site), and thus values ranged from 0 to 1. The number of frequency peaks was determined by counting the number of recordings with a peak within each of the 128 frequency bins that were equal or greater than the amplitude threshold. To control for the different number of
recordings in each site and each time interval (i.e., hour), we divided the number of recordings with a
peak in each time/frequency class by the total number of recordings collected during each hourly
interval.


To calculate ASU: 

- A. Aggregate recordings for a single day
```{r}
# List the path that contains all folders, which contain the audiomoth data
path <- "C:\\data\\"

# Listing the folders within which .WAV files are stored
folders <- dir(path, recursive=F,full.names=T)

# Now get only those files for a full 24 hours across every unique site
files <- list()

for(i in 1:length(folders)){

setwd(folders[1])
  
# List the files within each folder and renaming the files with the prefix - SITE_ID
a <- list.files(paste0(path,basename(folders)[1],"\\"), full.names = T)
file.rename(from = a, to=paste0(basename(folders)[1],"_",basename(a)))

site_date <- str_extract(basename(a),'\\w+_\\d+_')

# Choosing all 24 hours of data across every unique site (288 corresponds to 12 files every 1 hour)
  for(i in 1:length(unique(site_date))){
    dat <- a[str_detect(a,unique(site_date)[i])]
    if((length(a)<288)==TRUE){
      next
    } else {
      files <- c(files, dat) 
    }
  }
}

files <- unlist(files)
```

- B. Aggregate recordings for any single day for every unique site and sort it in order (between 00:00:00 to 23:55:00 hrs)
```{r}
# Get the subset of files for each unique site - a random day
# Select only 24 hours of data (00:00:00 to 23:55:00) for every unique site

subset <- list()

site <- str_extract(basename(files),'^([[:alnum:]])+')
unique(site)

# Select only 24 hours of data (00:00:00 to 23:55:00) for every unique site
for (i in 1:length(unique(site))){
  
  # Extract the strings site by site 
  b <- files[str_detect(files,unique(site)[i])]
  
  # Select any one random site_date combination
  site_date <- str_extract(basename(b),'\\w+_\\d+_')
  comb <- sample(site_date,1)
  dat <- b[str_detect(b,comb)]
  
  subset <- c(subset,dat)
}

subset <- unlist(subset)
```


- C. 
```{r}

# Trial using seewave::acoustat()

wave <- a
f <- 48000
wl <- 512
ovlp <- 0
wn <- "hanning"
n <- length(wave)

## Short-term Fourier transform (based on a R::seewave internal function)
m <- sspectro(wave, f = f, wl = wl, ovlp = ovlp, wn = wn)

# frequency selection and frequency axis
# Here, want only a sequence of numbers that correspond to the length of rows of the
# short-term fourier transform and we divide it by 1000 to get values in kHz
freq <- seq(0, (f/2) - (f/wl), length.out = nrow(m))/1000

## TIME AXIS
## A sequence of numbers that goes from 0 to 240 seconds, for the length of the nyquist frequency ## sampling rate/2
time <- seq(0, n/f, length.out = ncol(m))

## CONTOURS

t.cont <- apply(m, MARGIN = 2, FUN = sum)
f.cont <- apply(m, MARGIN = 1, FUN = sum)
t.cont <- t.cont/sum(t.cont)
f.cont <- f.cont/sum(f.cont)
t.cont.cum <- cumsum(t.cont)
f.cont.cum <- cumsum(f.cont)


## STATISTICS
fraction <-  90
P <- fraction/100
proportions <- as.matrix(c((1 - P)/2, 0.5, P + (1 - P)/2))
t.quantiles <- apply(proportions, MARGIN = 1, function(x) time[length(t.cont.cum[t.cont.cum <= 
        x]) + 1])
f.quantiles <- apply(proportions, MARGIN = 1, function(x) freq[length(f.cont.cum[f.cont.cum <= 
        x]) + 1])
    time.P1 <- t.quantiles[1]
    time.M <- t.quantiles[2]
    time.P2 <- t.quantiles[3]
    time.IPR <- time.P2 - time.P1
    freq.P1 <- f.quantiles[1]
    freq.M <- f.quantiles[2]
    freq.P2 <- f.quantiles[3]
    freq.IPR <- freq.P2 - freq.P1
    results <- list(time.contour = cbind(time = time, contour = t.cont), 
        freq.contour = cbind(frequency = freq, contour = f.cont), 
        time.P1 = time.P1, time.M = time.M, time.P2 = time.P2, 
        time.IPR = time.IPR, freq.P1 = freq.P1, freq.M = freq.M, 
        freq.P2 = freq.P2, freq.IPR = freq.IPR)



list_wavs <- list()

for (i in 1:length(subset)){
  r <- tuneR::readWave(subset[i])
  list_wavs <- c(list_wavs,r)
}

trial <- do.call(bind,list_wavs[80:100])

met <- acoustat(trial, f=48000)








```






we will first get values for the mean frequency spectrum and calculate frequency peaks
```{r}
# Calculate mean frequency spectrum
# This function returns the mean frequency spectrum (i.e. the mean relative amplitude of the frequency distribution) of a time wave. Results can be expressed either in absolute or dB data.
mf <- meanspec(a,f=48000,wl=256,norm=F)

# This graphical function returns a frequency spectrum as a bar plot.
f_bands <- fbands(mf)

# Calculate frequency peaks
# This function searches for peaks of a frequency spectrum.
# Setting a threshold of 172, as specified in previous papers
f_peak <- fpeaks(mf, threshold = 0.003, freq = 172)
```


Space Use calculation
```{r}
# Window length for the spectro and spec functions to keep each row every 10Hz
# Frequencies and seconds covered by each
freq_per_row <- 172 # This is the frequency bin size in Hz, which corresponds to ~ 140 bins for a nyquist rate of 24000 Hz

# Set an amplitude threshold
db_threshold <- -50

# Set the max freqency that can be used
# This is often the nyquist frequency which is calculated as sampling frequency/2
samplingrate <- 48000
max_freq <- samplingrate/2

# Set the Window length 
wlen <- samplingrate/freq_per_row

# This function returns a two-dimension spectrographic representation of a time wave. The function corresponds to short-term Fourier transform. An amplitude contour plot can be overlaid.
spec <- spectro(a, f = samplingrate, wl = wlen, plot = FALSE)$amp

# Setting frequency steps
freq_step <- 1000

# A sequence of frequencies
Freq <- seq(from = 0, to = max_freq - freq_step, by = freq_step)

# Borrowing a function from the soundecology package
# Function that gets the proportion of values over a db value in a specific band of frequencies. Frequency is in Hz
getscore <- function(spectrum, minf, maxf, db, freq_row){
		miny<-round((minf)/freq_row)
		maxy<-round((maxf)/freq_row)
		
		subA = spectrum[miny:maxy,]
		
		index1 <- length(subA[subA>db]) / length(subA)
		
		return(index1)
}

Score <- rep(NA, length(Freq))
for (i in 1:length(Freq)) {
			Score[i] = getscore(spec, Freq[i], (Freq[i] + freq_step), db_threshold, freq_per_row)
		}



```





Campos-Cerqueira et al., 2019 inputs:
For meanspec: f=44,100, wl = 256, wn = ‘hanning’, norm = FALSE
Audio waveforms scaled between -1 and 1
Spectral peaks limited to max. amplitude of 1
Amplitude threshold = 0.003
Counted number of recordings with a peak in each of the 128 frequency bins (given amplitude threshold)